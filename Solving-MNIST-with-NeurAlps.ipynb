{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralps.diffops import Linear, ReLU, DropOut, Softmax\n",
    "from neuralps.loss import CategoricalCrossEntropy\n",
    "from neuralps.metrics import multi_class_accuracy\n",
    "from neuralps.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preparing the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist.npz')\n",
    "\n",
    "vectors_train = mnist['train'].T\n",
    "train_size = vectors_train.shape[0]\n",
    "\n",
    "vectors_test = mnist['test'].T\n",
    "test_size = vectors_test.shape[0]\n",
    "\n",
    "labels_train = mnist['train_labels'].flatten().astype(int)\n",
    "labels_test = mnist['test_labels'].flatten().astype(int)\n",
    "\n",
    "n_classes = 10\n",
    "n_features = vectors_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_train = vectors_train.reshape(-1, 28, 28)\n",
    "\n",
    "sample_image = images_train[np.random.randint(0, train_size)]\n",
    "plt.imshow(sample_image, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_train.min(), vectors_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectors_train / 255.\n",
    "X_test = vectors_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.zeros((train_size, n_classes))\n",
    "y_test = np.zeros((test_size, n_classes))\n",
    "\n",
    "y_train[np.arange(train_size), labels_train] = 1\n",
    "y_test[np.arange(test_size), labels_test] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      " - train loss: 0.0316     acc: 0.9122\n",
      " - val  loss: 0.0307     acc: 0.9164\n",
      "EPOCH 1\n",
      " - train loss: 0.0288     acc: 0.9201\n",
      " - val  loss: 0.0284     acc: 0.9206\n",
      "EPOCH 2\n",
      " - train loss: 0.0274     acc: 0.9230\n",
      " - val  loss: 0.0275     acc: 0.9225\n",
      "EPOCH 3\n",
      " - train loss: 0.0267     acc: 0.9257\n",
      " - val  loss: 0.0269     acc: 0.9257\n",
      "EPOCH 4\n",
      " - train loss: 0.0263     acc: 0.9269\n",
      " - val  loss: 0.0269     acc: 0.9257\n",
      "EPOCH 5\n",
      " - train loss: 0.0257     acc: 0.9286\n",
      " - val  loss: 0.0266     acc: 0.9252\n",
      "EPOCH 6\n",
      " - train loss: 0.0255     acc: 0.9282\n",
      " - val  loss: 0.0266     acc: 0.9252\n",
      "EPOCH 7\n",
      " - train loss: 0.0252     acc: 0.9307\n",
      " - val  loss: 0.0265     acc: 0.9248\n",
      "EPOCH 8\n",
      " - train loss: 0.0249     acc: 0.9312\n",
      " - val  loss: 0.0263     acc: 0.9277\n",
      "EPOCH 9\n",
      " - train loss: 0.0249     acc: 0.9312\n",
      " - val  loss: 0.0263     acc: 0.9261\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "softmax_regression = Model(\n",
    "    Linear(n_features, n_classes),\n",
    "    Softmax()\n",
    ")\n",
    "\n",
    "softmax_regression.train(\n",
    "    X_train, y_train,\n",
    "    loss_function=CategoricalCrossEntropy,\n",
    "    batch_size=50,\n",
    "    epochs=10,\n",
    "    algorithm='rmsprop',\n",
    "    learning_rate=.001,\n",
    "    metric=multi_class_accuracy,\n",
    "    verbose=True,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      " - train loss: 0.0152     acc: 0.9554\n",
      " - val  loss: 0.0155     acc: 0.9546\n",
      "EPOCH 1\n",
      " - train loss: 0.0108     acc: 0.9678\n",
      " - val  loss: 0.0117     acc: 0.9638\n",
      "EPOCH 2\n",
      " - train loss: 0.0092     acc: 0.9724\n",
      " - val  loss: 0.0101     acc: 0.9694\n",
      "EPOCH 3\n",
      " - train loss: 0.0078     acc: 0.9765\n",
      " - val  loss: 0.0096     acc: 0.9717\n",
      "EPOCH 4\n",
      " - train loss: 0.0070     acc: 0.9799\n",
      " - val  loss: 0.0092     acc: 0.9732\n",
      "EPOCH 5\n",
      " - train loss: 0.0061     acc: 0.9817\n",
      " - val  loss: 0.0087     acc: 0.9771\n",
      "EPOCH 6\n",
      " - train loss: 0.0054     acc: 0.9843\n",
      " - val  loss: 0.0081     acc: 0.9766\n",
      "EPOCH 7\n",
      " - train loss: 0.0052     acc: 0.9845\n",
      " - val  loss: 0.0081     acc: 0.9777\n",
      "EPOCH 8\n",
      " - train loss: 0.0047     acc: 0.9863\n",
      " - val  loss: 0.0075     acc: 0.9791\n",
      "EPOCH 9\n",
      " - train loss: 0.0045     acc: 0.9866\n",
      " - val  loss: 0.0080     acc: 0.9782\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n_hidden_units = 512\n",
    "keep_prob = .25\n",
    "\n",
    "mlp = Model(\n",
    "    Linear(n_features, n_hidden_units),\n",
    "    ReLU(),\n",
    "    DropOut(keep_prob),\n",
    "    Linear(n_hidden_units, n_classes),\n",
    "    Softmax()\n",
    ")\n",
    "\n",
    "mlp.train(\n",
    "    X_train, y_train,\n",
    "    loss_function=CategoricalCrossEntropy,\n",
    "    batch_size=50,\n",
    "    epochs=10,\n",
    "    algorithm='rmsprop',\n",
    "    learning_rate=.001,\n",
    "    metric=multi_class_accuracy,\n",
    "    verbose=True,\n",
    "    X_val=X_test,\n",
    "    y_val=y_test,\n",
    "    save_best_model='mlp-mnist.npz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp = Model.load('mlp-mnist.npz')\n",
    "\n",
    "y_pred = loaded_mlp.predict(X_test)\n",
    "\n",
    "multi_class_accuracy(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
